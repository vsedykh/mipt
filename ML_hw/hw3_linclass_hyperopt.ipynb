{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная (и не очень) классификация\n",
    "\n",
    "Эта домашняя работа состоит из двух частей:\n",
    "\n",
    "1. В первой части задания вам предстоит узнать, как с помощью [kernel trick](https://ru.wikipedia.org/wiki/%D0%AF%D0%B4%D0%B5%D1%80%D0%BD%D1%8B%D0%B9_%D0%BC%D0%B5%D1%82%D0%BE%D0%B4) и создания новых признаков превратить ваш линейный классификатор в нелинейный.\n",
    "\n",
    "2. Во второй части вы попрактикуетесь в отборе гиперпараметров, а также обучите и выберете лучшую модель из всех уже изученных на задаче многоклассовой классификации автомобилей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Часть 1: нелинейные линейные модели\n",
    "\n",
    "Линейные модели являются одними из простейших, хорошо интерпретируемых и не склонных к переобучению среди всех алгоритмов машинного обучения. Однако их мощности и выразительной способности может не хватать для решения достаточно сложных задач. Ниже вы проиллюстрируете эту проблему на примере задачи бинарной классификации с линейно неразделимыми классами и попробуете решить её доступными методами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T23:26:22.240114Z",
     "start_time": "2019-03-13T23:26:21.327520Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57f562bf4f554fae",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons, make_circles\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмём для демонстрации игрушечный датасет [make_moons](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T23:26:22.247247Z",
     "start_time": "2019-03-13T23:26:22.242895Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee8cf8e9cf114b9d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "moons_points, moons_labels = make_moons(n_samples=500, noise=0.2, random_state=42)\n",
    "\n",
    "class_to_color = {0: 'red', 1: 'blue'}\n",
    "plt.scatter(moons_points[:, 0], moons_points[:, 1], c=[class_to_color[label] for label in moons_labels])\n",
    "plt.title('Датасет')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-35b09404d22ab9f4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 1.1 Линейные модели из коробки\n",
    "Давайте попробуем начать с использования логистической регрессии и метода опорных векторов.\n",
    "\n",
    "Обучите оба классификатора и нарисуйте решающую поверхность и классифицируемые регионы. **Не забудьте поделить данные на обучающие и тестовые!** Также выберите какую нибудь [метрику](https://scikit-learn.org/stable/api/sklearn.metrics.html#classification-metrics)  классификации и оцените с помощью неё качество на обучающих и тестовых данных. Опишите результаты в одном-двух предложениях.\n",
    "\n",
    "Подсказка: чтобы нарисовать классифицируемые области вы можете вдохновиться [примерами](https://scikit-learn.org/stable/auto_examples/neural_networks/plot_mlp_alpha.html#sphx-glr-auto-examples-neural-networks-plot-mlp-alpha-py) из sklearn-а или воспользоваться готовой функцией `plot_decision_regions` из пакета [mlxtend](https://github.com/rasbt/mlxtend) (см. примеры по ссылке)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T23:26:22.846438Z",
     "start_time": "2019-03-13T23:26:22.482543Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-550546e70e191bc3",
     "locked": false,
     "points": 10,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "lr = LogisticRegression()\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Kernel trick\n",
    "\n",
    "Теперь попробуйте поиграться с кернелами в методе опорных векторов. Используйте различные кернелы (`poly`, `rbf`, `sigmoid`) для получения наилучшего результата.\n",
    "\n",
    "Для каждого кернела постройте свой график с классифицируемыми регионами и посчитайте ранее выбранную метрику.\n",
    "\n",
    "Опишите в нескольких предложениях\n",
    "\n",
    "* Как использование кернелов повлияло на качество классификации?\n",
    "* Как изменилась решающая поверхность для каждого кернела?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T23:26:22.864832Z",
     "start_time": "2019-03-13T23:26:22.862013Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3a1681e6d52ed236",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba9a59e3ec57f514",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 1.3 Более простое решение\n",
    "А как можно было бы решить поставленную задачу и построить нелинейную разделяющую поверхность с помощью логистической регрессии? В этом может помочь создание новых признаков. В данном случае вам предлагается добавить признаки, имеющие вид произведений исходных признаков.\n",
    "\n",
    "За этим стоит простая идея. Решающая поверхность в случае логистической регрессии с двумя признаками задаётся уравнением прямой или, что то же самое, уравнением линии уровня решающей функции со значением 0:\n",
    "$$ \\omega_0 + x_1 \\cdot \\omega_1 + x_2 \\cdot \\omega_2 = 0.$$\n",
    "Если мы добавим объектам признаки $x_1 \\cdot x_2$, $x_1^2$, $x_2^2$, то уравнение решающей поверхности примет вид\n",
    "\n",
    "$$ \\omega_0 + x_1 \\cdot \\omega_1 + x_2 \\cdot \\omega_2 + x_1 \\cdot x_2 \\cdot \\omega_3 + x_1^2 \\cdot \\omega_4 + x_2^2 \\cdot \\omega_5 = 0.$$\n",
    "Это уравнение задаёт гиперплоскость (линейную разделяющую поверхность) в новом (2 + 3)-мерном пространстве признаков, однако в исходном двумерном пространстве оно задаёт некоторую нелинейную кривую.\n",
    "\n",
    "Необязательно добавлять в качестве новых признаков именно полиномы от старых признаков. Можно подойти к вопросу творчески и добавлять произвольные нелинейные комбинации признаков: $\\log x_1$, $\\exp(x_2)$, $\\log\\left(\\dfrac{x_2^2 \\cdot x_1 + \\pi}{\\exp(x_1 \\cdot x_2^{0.3}) + 1}\\right)$ и т.д. Чем больше сложных нелинейных признаков вы добавите, тем большую мощность обретёт ваша исходно слабая линейная модель. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В коде ниже добавьте объектам датасета полиномиальные признаки с помощью класса [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) и аналогично предыдущему пункту обучите логистическую регрессию, изобразите классифицируемые области и посчитайте выбранную метрику.\n",
    "\n",
    "В данном случае с практической точки зрения удобно считать создание новых признаков не этапом работы с данными, а одним из шагов алгоритма. Попробуйте объединить создание полиномиальных признаков и работу классификатора в один алгоритм с помощью [make_pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html). Эта функция может вам понадобиться и во второй части работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T23:26:22.869584Z",
     "start_time": "2019-03-13T23:26:22.866757Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-58a1e03cab2ca349",
     "locked": false,
     "points": 15,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-868839a4a8358c59",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 1.4 Более сложная задача\n",
    "\n",
    "Сделаем задачу чуть сложнее, объединив несколько игрушечных датасетов в один:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T23:26:23.084319Z",
     "start_time": "2019-03-13T23:26:22.876842Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86be614f32559cea",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "class_to_color = {0: 'red', 1: 'blue', 2: 'green', 3: 'orange'}\n",
    "circles_points, circles_labels = make_circles(n_samples=500, noise=0.06, random_state=42)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(circles_points[:, 0], circles_points[:, 1], c=[class_to_color[label] for label in circles_labels])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T23:26:23.326325Z",
     "start_time": "2019-03-13T23:26:23.086480Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7a98ef8e43822e61",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "points = np.vstack((circles_points*2.5 + 0.5, moons_points))\n",
    "labels = np.hstack((circles_labels, moons_labels + 2))\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(points[:, 0], points[:, 1], c=[class_to_color[label] for label in labels])\n",
    "plt.title('Датасет')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7c2a785a2d63ce73",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Попробуйте решить эту задачу с помощью подходов, изученных ранее. \n",
    "\n",
    "Подберите наилучшие параметры для степени полиномиальных признаков для логистической регрессии и наилучшие параметры для ядер метода опорных векторов.\n",
    "\n",
    "Также вы можете опробовать на этой задаче другие изученные модели - [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) и [наивный байесовский классификатор](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html).\n",
    "\n",
    "Опишите полученные результаты в нескольких предложениях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T23:26:23.330584Z",
     "start_time": "2019-03-13T23:26:23.328232Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e61b36ea61909c83",
     "locked": false,
     "points": 40,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: подбор гиперпараметров и тюнинг моделей\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части задания вы будете работать с датасетом описаний автомобилей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скачивание данных\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1hDbmoa1g-EmtFMgvXWlutY53aC6v53y4' -O car_data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код ниже делит данные на обучающие и тестовые, **не меняйте его!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Загрузка данных\n",
    "dataset = pd.read_csv('car_data.csv', delimiter=',', header=None).values\n",
    "data = dataset[:, :-1].astype(int)\n",
    "target = dataset[:, -1]\n",
    "\n",
    "print(data.shape, target.shape)\n",
    "\n",
    "# Разделение на обучающие и тестовые данные\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.35, random_state=42)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "print(f'{len(np.unique(target))} класса: {np.unique(target)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для разведывательного анализа данных удобно использовать библиотеку [pandas](https://pandas.pydata.org/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pd = pd.DataFrame(X_train)\n",
    "\n",
    "# Покаывает первые 15 строчек датасета\n",
    "X_train_pd.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод `describe` показывает некоторые статистики признаков датасета\n",
    "# Например он показывает средние значения (mean), стандартные отклонения (std), максимумы (max) и минимумы (min) признаков и другое\n",
    "X_train_pd.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрики выберем `Accuracy`\n",
    "\n",
    "В качестве бейзлайна давайте возьмём классификатор, предсказывающий самый популярный класс из обучающего датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class MostFrequentClassifier:\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.most_frequent_label = Counter(y_train).most_common(1)[0][0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.full(X.shape[0], self.most_frequent_label)\n",
    "\n",
    "baseline_classifier = MostFrequentClassifier()\n",
    "baseline_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(f'Accuracy бейзлайна: {accuracy_score(baseline_classifier.predict(X_test), y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всегда важно иметь в арсенале простое, возможно некачественное, но интерпретируемое решение задачи - бейзлайн. Далее при обучении более сложных моделей можно будет отталкиваться от метрики, полученной бейзлайном. Если более сложная модель получила меньшее значение метрики, значит видимо что-то идёт не так и необходимо проанализировать где могла случиться проблема."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор гиперпараметров\n",
    "\n",
    "Подбор гиперпараметров - довольно сложная задача, так как обычно гиперпараметры нельзя подобрать сильно более оптимальным образом, чем перебором. В sklearn для подбора гиперпараметров есть [набор](https://scikit-learn.org/stable/api/sklearn.model_selection.html#hyper-parameter-optimizers) простых стратегий, например таких как\n",
    "* [Поиск по сетке](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#gridsearchcv)\n",
    "* [Рандомизированный поиск](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)\n",
    "\n",
    "Для более \"умного\" подбора гиперпараметров существуют специально предназначенные для этого библиотеки, например [optuna](https://optuna.org/).\n",
    "\n",
    "Давайте попробуем запустить поиск по сетке каких нибудь параметров логистической регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Словарь \"параметр\" -> \"сетка поиска\"\n",
    "params_to_search = {'C': [0.5, 1, 2], 'penalty': ['l1', 'l2'], 'max_iter': [250, 500]}\n",
    "\n",
    "# Создаём объект класса `GridSearchCV` - поиска по сетке\n",
    "# В конструктор класса подаётся классификатор, параметры которого мы будем перебирать и словарь параметров\n",
    "cv = GridSearchCV(LogisticRegression(solver='saga'), params_to_search)\n",
    "\n",
    "# Метод `fit` последовательно обучает переданную модель со всеми комбинациями параметров из `params_to_search`\n",
    "# Оценка комбинации параметров происходит с помощью кросс-валидации по 5 фолдам (можно настраивать это значение)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лучшими значениями параметров считаются те, которые дают наибольший средний `score` модели на обучающей выборке\n",
    "# Таким образом алгоритм, поданный на вход `GridSearchCV` должен иметь метод `score`, оценивающий его качество\n",
    "# Для `LogisticRegression` `score`-ом является Accuracy\n",
    "lr = LogisticRegression(solver='saga')\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test), accuracy_score(lr.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# У `GridSearchCV` есть метод `predict`, считающий предсказания для модели с наилучшими значениями параметров\n",
    "y_test_best_model = cv.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test_best_model, y_test))\n",
    "\n",
    "# Наилучшие значения параметров можно достать так\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Различные результаты перебора гиперпараметров можно достать так\n",
    "cv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Покажите класс!\n",
    "\n",
    "Теперь, зная как подбирать гиперпараметры и обучать модели, попробуйте обучить модель, дающую $\\mathbf{\\geq 0.85}$ Accuracy на тестовых данных. Вы в праве выбирать любую изученную модель и любые её гиперпараметры. Также вы можете предобрабатывать данные любым образом (нормализовать, генерировать дополнительные признаки и т.д.). Единственное что запрещено - менять то, как данные разделены на трейн и тест и обучаться на тестовых данных.\n",
    "\n",
    "**Дерзайте!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
